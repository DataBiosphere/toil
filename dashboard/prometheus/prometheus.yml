# my global config
    global:
      scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
      evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
      # scrape_timeout is set to the global default (10s).

      # Attach these labels to any time series or alerts when communicating with
      # external systems (federation, remote storage, Alertmanager).
      external_labels:
          monitor: 'codelab-monitor'

    # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
    rule_files:
      # - "first.rules"
      # - "second.rules"

    # A scrape configuration containing exactly one endpoint to scrape:
    # Here it's Prometheus itself.
    scrape_configs:
      # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
      - job_name: 'prometheus'

        # metrics_path defaults to '/metrics'
        # scheme defaults to 'http'.

        static_configs:
          - targets: ['localhost:9090']
      - job_name: 'toil'
        static_configs:
          - targets: ['localhost:3903']
      - job_name: 'node'
        static_configs:
          - targets: ['localhost:9100']
      - job_name: 'aws-node-exporter'
        ec2_sd_configs:
          - region: 'us-west-2'
            refresh_interval: 15s
            port: 9100
        relabel_configs:
          - source_labels: ['__meta_ec2_tag_Name']
            action: keep
            regex: CLUSTER_NAME
          - source_labels: ['__meta_ec2_instance_state']
            action: drop
            regex: '.*(stopped|terminated).*'

